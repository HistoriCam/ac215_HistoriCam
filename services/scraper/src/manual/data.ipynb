{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manual Curation Workflow\n",
    "\n",
    "Curate 10-20 high-quality buildings/statues with manual images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, csv, hashlib, time\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from typing import Dict, List, Optional, Tuple\n",
    "from PIL import Image\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ 1 items to curate\n"
     ]
    }
   ],
   "source": [
    "CURATED_ITEMS = [\n",
    "    {\"name\": \"Widener Library\", \"type\": \"building\"},\n",
    "    {\"name\": \"Massachusetts Hall\", \"type\": \"building\"},\n",
    "    {\"name\": \"University Hall\", \"type\": \"building\"},\n",
    "    {\"name\": \"Memorial Church\", \"type\": \"building\"},\n",
    "    {\"name\": \"Sever Hall\", \"type\": \"building\"},\n",
    "    {\"name\": \"Harvard Hall\", \"type\": \"building\"},\n",
    "    {\"name\": \"Harvard Science Center\", \"type\": \"building\"},\n",
    "    {\"name\": \"Memorial Hall\", \"type\": \"building\"},\n",
    "    {\"name\": \"John Harvard Statue\", \"type\": \"statue\"},\n",
    "    {\"name\": \"Johnston Gate\", \"type\": \"gate\"},\n",
    "    {\"name\": \"Dexter Gate\", \"type\": \"gate\"},\n",
    "    {\"name\": \"Tanner Fountain\", \"type\": \"fountain\"},\n",
    "    {\"name\": \"Meyer Gate\", \"type\": \"gate\"},\n",
    "    {\"name\": \"Harvard Art Museums\", \"type\": \"building\"},\n",
    "    {\"name\": \"Harvard Lampoon Building\", \"type\": \"building\"},\n",
    "    {\"name\": \"Lowell House\", \"type\": \"building\"},\n",
    "    {\"name\": \"Weld Boathouse\", \"type\": \"building\"},\n",
    "    {\"name\": \"Weeks Footbridge\", \"type\": \"bridge\"},\n",
    "    {\"name\": \"Langdell Hall\", \"type\": \"building\"},\n",
    "    {\"name\": \"Smith Campus Center\", \"type\": \"building\"},\n",
    "    {\"name\": \"Science and Engineering Complex\", \"type\": \"building\"},\n",
    "]\n",
    "\n",
    "OUTPUT_DIR = Path(\"/Users/hughv/Documents/Harvard/AC215/ac215_HistoriCam/data_manual\")\n",
    "USER_AGENT = \"HistoriCam/1.0 (Educational project; contact: hughvandeventer@g.harvard.edu)\"\n",
    "WIKIPEDIA_API = \"https://en.wikipedia.org/w/api.php\"\n",
    "print(f\"✓ {len(CURATED_ITEMS)} items to curate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Wikipedia search functions defined\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Wikipedia Search Functions\n",
    "\n",
    "def search_wikipedia(query: str, session: requests.Session, limit: int = 5) -> List[Tuple[str, str]]:\n",
    "    \"\"\"Search Wikipedia using opensearch API. Returns list of (title, description) tuples.\"\"\"\n",
    "    params = {\"action\": \"opensearch\", \"search\": query, \"limit\": limit, \"format\": \"json\", \"namespace\": 0}\n",
    "    try:\n",
    "        r = session.get(WIKIPEDIA_API, params=params, timeout=30)\n",
    "        r.raise_for_status()\n",
    "        data = r.json()\n",
    "        titles = data[1] if len(data) > 1 else []\n",
    "        descriptions = data[2] if len(data) > 2 else [\"\"] * len(titles)\n",
    "        return list(zip(titles, descriptions))\n",
    "    except Exception as e:\n",
    "        print(f\"  Error searching: {e}\")\n",
    "        return []\n",
    "\n",
    "def get_pageid_from_title(title: str, session: requests.Session) -> Optional[int]:\n",
    "    \"\"\"Get pageid for a Wikipedia page title.\"\"\"\n",
    "    params = {\"action\": \"query\", \"titles\": title, \"format\": \"json\"}\n",
    "    try:\n",
    "        r = session.get(WIKIPEDIA_API, params=params, timeout=30)\n",
    "        r.raise_for_status()\n",
    "        pages = r.json()[\"query\"][\"pages\"]\n",
    "        pageid = list(pages.keys())[0]\n",
    "        return None if pageid == \"-1\" else int(pageid)\n",
    "    except Exception as e:\n",
    "        print(f\"  Error getting pageid: {e}\")\n",
    "        return None\n",
    "\n",
    "def fetch_page_details(pageid: int, session: requests.Session) -> Optional[Dict]:\n",
    "    \"\"\"Fetch metadata for a Wikipedia page (coordinates, QID, aliases).\"\"\"\n",
    "    params = {\n",
    "        \"action\": \"query\", \"format\": \"json\", \"prop\": \"coordinates|pageprops|pageterms\",\n",
    "        \"pageids\": str(pageid), \"coprop\": \"type|dim|name|country|region|globe\",\n",
    "        \"ppprop\": \"wikibase_item\", \"wbptterms\": \"alias\"\n",
    "    }\n",
    "    try:\n",
    "        r = session.get(WIKIPEDIA_API, params=params, timeout=30)\n",
    "        r.raise_for_status()\n",
    "        page = r.json()[\"query\"][\"pages\"][str(pageid)]\n",
    "        coords = page.get(\"coordinates\", [{}])[0]\n",
    "        aliases = page.get(\"terms\", {}).get(\"alias\", [])\n",
    "        return {\n",
    "            \"title\": page[\"title\"], \"pageid\": pageid,\n",
    "            \"url\": f\"https://en.wikipedia.org/?curid={pageid}\",\n",
    "            \"lat\": coords.get(\"lat\"), \"lon\": coords.get(\"lon\"),\n",
    "            \"qid\": page.get(\"pageprops\", {}).get(\"wikibase_item\"),\n",
    "            \"aliases\": \"|\".join(aliases) if aliases else \"\"\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"  Error fetching details: {e}\")\n",
    "        return None\n",
    "\n",
    "def interactive_search_and_select(item: Dict, session: requests.Session) -> Optional[Dict]:\n",
    "    \"\"\"Search Wikipedia and let user select correct match.\"\"\"\n",
    "    results = search_wikipedia(item[\"name\"], session, limit=5)\n",
    "    if not results:\n",
    "        print(f\"  No results for '{item['name']}'\")\n",
    "        return None\n",
    "    \n",
    "    print(f\"\\n  Found {len(results)} results:\")\n",
    "    for idx, (title, desc) in enumerate(results):\n",
    "        print(f\"    [{idx}] {title}\")\n",
    "        if desc:\n",
    "            print(f\"        {desc[:80]}...\")\n",
    "    \n",
    "    while True:\n",
    "        choice = input(f\"\\n  Select [0-{len(results)-1}] or 's' to skip: \").strip().lower()\n",
    "        if choice == 's':\n",
    "            return None\n",
    "        try:\n",
    "            idx = int(choice)\n",
    "            if 0 <= idx < len(results):\n",
    "                selected_title = results[idx][0]\n",
    "                print(f\"  Selected: {selected_title}\")\n",
    "                pageid = get_pageid_from_title(selected_title, session)\n",
    "                if pageid:\n",
    "                    details = fetch_page_details(pageid, session)\n",
    "                    if details:\n",
    "                        details[\"manual_type\"] = item.get(\"type\", \"unknown\")\n",
    "                        return details\n",
    "                return None\n",
    "        except ValueError:\n",
    "            pass\n",
    "        print(\"  Invalid choice\")\n",
    "\n",
    "print(\"✓ Wikipedia search functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Wikipedia search for 1 items...\n",
      "\n",
      "============================================================\n",
      "\n",
      "[1/1] Searching for: Science and Engineering Complex\n",
      "  No results for 'Science and Engineering Complex'\n",
      "  ✗ Skipped\n",
      "\n",
      "============================================================\n",
      "SEARCH COMPLETE\n",
      "============================================================\n",
      "✓ Found: 0 pages\n",
      "✗ Skipped: 1 items\n",
      "\n",
      "Skipped items:\n",
      "  - Science and Engineering Complex\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: Execute Wikipedia Search\n",
    "\n",
    "session = requests.Session()\n",
    "session.headers.update({'User-Agent': USER_AGENT})\n",
    "\n",
    "found_pages = []\n",
    "skipped_items = []\n",
    "\n",
    "print(f\"Starting Wikipedia search for {len(CURATED_ITEMS)} items...\\n\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for idx, item in enumerate(CURATED_ITEMS, 1):\n",
    "    print(f\"\\n[{idx}/{len(CURATED_ITEMS)}] Searching for: {item['name']}\")\n",
    "    \n",
    "    if 'pageid' in item:\n",
    "        print(f\"  Using manually provided pageid: {item['pageid']}\")\n",
    "        details = fetch_page_details(item['pageid'], session)\n",
    "        if details:\n",
    "            details['manual_type'] = item.get('type', 'unknown')\n",
    "            found_pages.append(details)\n",
    "            print(f\"  ✓ Found: {details['title']}\")\n",
    "        else:\n",
    "            print(f\"  ✗ Failed to fetch details\")\n",
    "            skipped_items.append(item)\n",
    "    else:\n",
    "        details = interactive_search_and_select(item, session)\n",
    "        if details:\n",
    "            found_pages.append(details)\n",
    "            print(f\"  ✓ Added to curated list\")\n",
    "        else:\n",
    "            print(f\"  ✗ Skipped\")\n",
    "            skipped_items.append(item)\n",
    "    \n",
    "    time.sleep(0.5)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SEARCH COMPLETE\")\n",
    "print(\"=\"*60)\n",
    "print(f\"✓ Found: {len(found_pages)} pages\")\n",
    "print(f\"✗ Skipped: {len(skipped_items)} items\")\n",
    "\n",
    "if skipped_items:\n",
    "    print(\"\\nSkipped items:\")\n",
    "    for item in skipped_items:\n",
    "        print(f\"  - {item['name']}\")\n",
    "\n",
    "if found_pages:\n",
    "    print(\"\\nFound pages:\")\n",
    "    for p in found_pages:\n",
    "        coord_str = f\"({p['lat']:.4f}, {p['lon']:.4f})\" if p.get('lat') and p.get('lon') else \"(no coords)\"\n",
    "        print(f\"  {p['title']} - {coord_str} - {p.get('qid', 'no QID')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating CSV files...\n",
      "\n",
      "✓ Created buildings_names.csv\n",
      "✓ Created buildings_names_metadata.csv\n",
      "✓ Created buildings_info.csv (stub)\n",
      "\n",
      "✓ All CSVs generated in /Users/hughv/Documents/Harvard/AC215/ac215_HistoriCam/data_manual\n",
      "  Total buildings: 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/79/zqmschxs1415hjrwdb5kmblw0000gn/T/ipykernel_55781/3467520445.py:6: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  now = datetime.utcnow().isoformat()\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: Generate CSV Files\n",
    "\n",
    "def generate_buildings_csvs(pages: List[Dict], output_dir: Path) -> Tuple[Path, Path, Path]:\n",
    "    \"\"\"Generate buildings CSVs maintaining exact schema compatibility.\"\"\"\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    now = datetime.utcnow().isoformat()\n",
    "    \n",
    "    # buildings_names.csv\n",
    "    names_path = output_dir / \"buildings_names.csv\"\n",
    "    with open(names_path, 'w', newline='', encoding='utf-8') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow([\"id\", \"name\", \"source_url\", \"last_seen\", \"source\"])\n",
    "        for idx, page in enumerate(pages, start=1):\n",
    "            writer.writerow([idx, page['title'], page['url'], now, \"wikipedia\"])\n",
    "    print(f\"✓ Created {names_path.name}\")\n",
    "    \n",
    "    # buildings_names_metadata.csv\n",
    "    metadata_path = output_dir / \"buildings_names_metadata.csv\"\n",
    "    with open(metadata_path, 'w', newline='', encoding='utf-8') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow([\"id\", \"name\", \"source_url\", \"last_seen\", \"source\", \"latitude\", \"longitude\", \"aliases\", \"wikibase_item\"])\n",
    "        for idx, page in enumerate(pages, start=1):\n",
    "            writer.writerow([idx, page['title'], page['url'], now, \"wikipedia\",\n",
    "                           page.get('lat', ''), page.get('lon', ''), page.get('aliases', ''), page.get('qid', '')])\n",
    "    print(f\"✓ Created {metadata_path.name}\")\n",
    "    \n",
    "    # buildings_info.csv (stub)\n",
    "    info_path = output_dir / \"buildings_info.csv\"\n",
    "    with open(info_path, 'w', newline='', encoding='utf-8') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow([\"id\", \"name\", \"source_url\", \"built_year\", \"architect\", \"architectural_style\",\n",
    "                        \"location\", \"materials\", \"building_type\", \"owner\", \"height\", \"construction_cost\", \"unstructured_info\"])\n",
    "        for idx, page in enumerate(pages, start=1):\n",
    "            writer.writerow([idx, page['title'], page['url']] + [''] * 10)\n",
    "    print(f\"✓ Created {info_path.name} (stub)\")\n",
    "    \n",
    "    return names_path, metadata_path, info_path\n",
    "\n",
    "if not found_pages:\n",
    "    print(\"⚠ No pages found. Run Cell 4 first.\")\n",
    "else:\n",
    "    print(\"Generating CSV files...\\n\")\n",
    "    csv_paths = generate_buildings_csvs(found_pages, OUTPUT_DIR)\n",
    "    print(f\"\\n✓ All CSVs generated in {OUTPUT_DIR}\")\n",
    "    print(f\"  Total buildings: {len(found_pages)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Created image directories\n",
      "\n",
      "============================================================\n",
      "MANUAL STEP: Download Images\n",
      "============================================================\n",
      "\n",
      "Directories: /Users/hughv/Documents/Harvard/AC215/ac215_HistoriCam/data_manual/images\n",
      "\n",
      "Next steps:\n",
      "1. Navigate to each numbered directory (1/, 2/, etc.)\n",
      "2. Download images for corresponding building\n",
      "3. Any filename works - code will rename later\n",
      "4. Formats: JPEG, PNG, WebP\n",
      "5. Min: 512x512px, Max: 10MB per image\n",
      "\n",
      "Building ID to Name mapping:\n",
      "------------------------------------------------------------\n",
      "  1/ -> Widener Library\n",
      "  2/ -> Massachusetts Hall (Harvard University)\n",
      "  3/ -> Memorial Church of Harvard University\n",
      "  4/ -> Sever Hall\n",
      "  5/ -> Harvard Hall\n",
      "  6/ -> Harvard Science Center\n",
      "  7/ -> Memorial Hall (Harvard University)\n",
      "  8/ -> John Harvard Statue\n",
      "  9/ -> Johnston Gate\n",
      "  10/ -> Meyer Gate\n",
      "  11/ -> Harvard Art Museums\n",
      "  12/ -> Harvard Lampoon Building\n",
      "  13/ -> Lowell House\n",
      "  14/ -> Weld Boathouse\n",
      "  15/ -> Weeks Footbridge\n",
      "  16/ -> Langdell Hall\n",
      "  17/ -> Smith Campus Center\n",
      "------------------------------------------------------------\n",
      "\n",
      "Run Cell 7 after downloading images.\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: Setup Image Directories\n",
    "\n",
    "def setup_image_directories(num_buildings: int, output_dir: Path) -> Path:\n",
    "    \"\"\"Create empty image directories for each building.\"\"\"\n",
    "    images_dir = output_dir / \"images\"\n",
    "    images_dir.mkdir(exist_ok=True)\n",
    "    for building_id in range(1, num_buildings + 1):\n",
    "        (images_dir / str(building_id)).mkdir(exist_ok=True)\n",
    "    return images_dir\n",
    "\n",
    "if not found_pages:\n",
    "    print(\"⚠ No pages found. Run Cell 4 first.\")\n",
    "else:\n",
    "    images_dir = setup_image_directories(len(found_pages), OUTPUT_DIR)\n",
    "    print(\"✓ Created image directories\\n\")\n",
    "    print(\"=\"*60)\n",
    "    print(\"MANUAL STEP: Download Images\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"\\nDirectories: {images_dir}\")\n",
    "    print(\"\\nNext steps:\")\n",
    "    print(\"1. Navigate to each numbered directory (1/, 2/, etc.)\")\n",
    "    print(\"2. Download images for corresponding building\")\n",
    "    print(\"3. Any filename works - code will rename later\")\n",
    "    print(\"4. Formats: JPEG, PNG, WebP\")\n",
    "    print(\"5. Min: 512x512px, Max: 10MB per image\")\n",
    "    print(\"\\nBuilding ID to Name mapping:\")\n",
    "    print(\"-\" * 60)\n",
    "    for idx, page in enumerate(found_pages, start=1):\n",
    "        print(f\"  {idx}/ -> {page['title']}\")\n",
    "    print(\"-\" * 60)\n",
    "    print(\"\\nRun Cell 7 after downloading images.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing manual images from existing CSVs...\n",
      "============================================================\n",
      "\n",
      "[1] Widener Library: Processing 16 images...\n",
      "  ✓ 1cd72fd7ea8f57379d39bf4fe3d5d3079de69b5115802b94741c76b967b6b882.jpg (3872x1803px)\n",
      "  ✓ 4a83717a1b8fb0ff94eeffe0d8a2d779ddb0ec4fe5ecfd4d881aa56bb7c01374.jpg (2000x1499px)\n",
      "  ✓ be61ea6c5eadf07012b337e7ab25c6a9981c80ee2a97878bee20fb917fd23830.jpg (1920x1080px)\n",
      "  ✓ 7c321bcc1aa7f59970153ae2137f9ca92b8f0d1742fa09d3002bf05f2760e537.jpg (1024x683px)\n",
      "  ✓ ae50df860efa2142c49723adf99ef87387a7de188cecbfa92ea7bc554be551cb.jpg (1024x682px)\n",
      "  ✓ 8ea002a486a7bbc3e16ae788b9ad29d3716f7db4c232bd434058efb1374e5a97.jpg (3600x2316px)\n",
      "  ✓ 292000428a9cb8786761539b4ec978da7c66d72e897fc9632bf71f422b5d25de.jpg (2000x1348px)\n",
      "  ✓ 68cf501e6d230fb73c140b01910a97dfdac0177c19f972a40503c79cc5699180.jpg (1500x1000px)\n",
      "  ✓ 33855b2cf4523db5a5a1d1d3812d32ea3987f3e9d5c4e6e478c0e5ef17bb3dbc.jpg (1024x679px)\n",
      "  ✓ cd547c195fe85ea5f62ffe679643536b11d26e81f83e2a21f7ebd8c722267848.jpg (640x428px)\n",
      "  ✓ 0228ac4955deb73c4958306e43ec17b017438369973aa9682c2139e22a029fe9.jpg (795x571px)\n",
      "  ✓ 6ce0e51a0f1883c6008bef2a2c462a73ceb52e0696b65727d5eb53956d595713.jpg (533x400px)\n",
      "  ✓ 87fccb789e3063b5d9f3bcf37fa95f98b39e613085c96c91d19faa1c44eda98c.jpg (1999x1333px)\n",
      "  ✓ 901467a8ee65895ad303411d4289f45f68b3667ee3fe2b470429c510dc3f009c.jpg (2560x1707px)\n",
      "  ✓ b6674905ebd6159736124b10deac8bc307146e1141b87a0575dc72cdced9b781.jpg (1024x683px)\n",
      "  ✓ 527363b977afe60ab9d5ff6f943333a1f1c82e5bdffe26cfebbb745e6b5c2831.jpg (225x225px)\n",
      "\n",
      "[2] Massachusetts Hall (Harvard University): Processing 14 images...\n",
      "  ✓ 46c45327c8872a3dd5b2678d40909fddc2084e156edc2e742fa872c84c6d5a8c.jpg (1500x999px)\n",
      "  ✓ e79df1a910249ff92362bf6b08d0423ebc2210f92c7de8266a5cfd3be069e1c8.jpg (2560x1707px)\n",
      "  ✓ 7bfda9b1fe0bb4cc59baf84d1c98537cf80cdbe77c45026a738f56a87cf3a0dc.jpg (196x257px)\n",
      "  ✓ ffd9702a9934afe16825c643d4e2210237df224ad7e052146d76ce5f6efdcd97.jpg (2560x1920px)\n",
      "  ✓ eb2dd7cc7951387db0e8bde4f8602f75c87992eac1c290e92ce664a175a0c915.jpg (260x194px)\n",
      "  ✓ 99a1b5816d53af57c499e0e467d75b53255a7262a35f50fdab7df2f7e9836611.jpg (2560x1778px)\n",
      "  ✓ a63bfa81a20346742d01653b6e0573dcb4dfe6954188dfd713642e96cc8168ce.jpg (1024x683px)\n",
      "  ✓ a750e8770ce4bc227587055c37340067974d86c65d7e79d3cdad071eee4585c9.jpg (1024x683px)\n",
      "  ✓ c55612c2dfebd1d9376a885e5fb9ae699f88b0b69ce478abfabea8b426c1a0cf.jpg (511x768px)\n",
      "  ✓ 94068ba17a4adc77fa504813a336e59b7843852cd23a9a6ebfbf68e831b7ad52.jpg (1600x1159px)\n",
      "  ✓ 93d2eb9806164a26097206baf2e99835ffdcefd36ce9b6e749b4ea33fa531a58.jpg (923x660px)\n",
      "  ✓ 0f1e4599fcf5c69328d64f0e6f59b4f3815f38472d7a9f4926f74a3a83582fe2.jpg (1600x900px)\n",
      "  ✓ 8894a73094b88ee92413fc5d1727033863ded1f8536668b95482336f63d23734.jpg (1024x660px)\n",
      "  ✓ 5c8ab2d44d6fa75b1a301a42523524fcefb481ebb09f669b59c0021d02476737.jpg (2000x1333px)\n",
      "\n",
      "[3] Memorial Church of Harvard University: Processing 19 images...\n",
      "  ✓ 99be95f7b7d52a90d4a1d4c569a0d5094cc69b77b55d9e42a123b408b431d055.jpg (3441x5161px)\n",
      "  ✓ 9fec62ba6298515ea6e91969a3c1ed6461c7e3107246d33a35888ad8fe52b2fc.jpg (961x1440px)\n",
      "  ✓ 79bfc8fdb998a84326c85305b232f866acbdd5ebf7edadbb568e4c713926cd8b.jpg (427x640px)\n",
      "  ✓ d4c55380daa59b929ad5055f2adccbe77b0bfaf54d51bb5f0dc7b2f003e3ab9f.jpg (2009x1492px)\n",
      "  ✓ b7737034de547ce6eacf91864132c02017f6ebe1f3ce10693a55f692f36f8d03.jpg (183x276px)\n",
      "  ✓ d01b23417db335388151980698cc8249a3268a340ea3864fd30ea81f199175e0.jpg (900x720px)\n",
      "  ✓ 9c4e33fcce266f7f21d166f6d52f6dea88d5df6e716ebbaa7be28045c458b796.jpg (400x300px)\n",
      "  ✓ 36689cb8a97f31911ded689bc53391a752213e6ba3c9f52fb072068a569e118f.jpg (499x750px)\n",
      "  ✓ 87588db611a92fff4766f19728a21a44580848e24884b18e46e6828ff9fe691a.jpg (1200x1200px)\n",
      "  ✓ 7e345516a0bbb1db7191db20bd8a1f3f1e872ba025df6b3fdb90393f5c100623.jpg (510x768px)\n",
      "  ✓ 317ce148a9ddfbd9988f13949b3ef2f3080c24ae6ac4a3c03b84ac8fbde60516.jpg (1600x900px)\n",
      "  ✓ 2723807d4042ee6cedaf5f9b050ff4ff1594e4807b165982ff3f320d9097ccda.jpg (1920x685px)\n",
      "  ✓ 5c77419c3749c2a9e546606ca4f0fce658c6b77fdc63c51604f1a15c8392d2ff.jpg (1498x999px)\n",
      "  ✓ e4f44c5e8e266a2f9894dcb866b3129a62cd9329050e3ad1c42ae1a2fc363d26.jpg (980x551px)\n",
      "  ✓ f373936f28ba4955108d1d032bf94684d0d33967b471d61075d6c0abb1289af8.jpg (625x547px)\n",
      "  ✓ 1e9bd07653b2a1b523d5c35b215a4f37031a550d45b61e33657480d9e73a0b0b.jpg (1000x1333px)\n",
      "  ✓ 7ca656e79814cf25facbff1e71ac020e2a67f6ba29b94bd109c00513b75b0391.jpg (1280x853px)\n",
      "  ✓ 94403941308606a1fd0cfae704452844e95aa81f5b8e3b408c5faaa8ed5598ec.jpg (1500x1000px)\n",
      "  ✓ d97d36ea71000b7aca7d6f22d056f6a8014e9d2d2621a97acc9737c214fa504c.jpg (660x495px)\n",
      "\n",
      "[4] Sever Hall: Processing 19 images...\n",
      "  ✓ bef4dd357f9796e5b5afd3c5ca55aeb7b9a8958131b5b340efa2cad584e80bc1.jpg (2000x1333px)\n",
      "  ✓ b9ae45215144b38cac8285bdd1342f17dca2963b0db5b716171336f7367c21a4.jpg (1500x1096px)\n",
      "  ✓ dfca1a0a045197b28cbcae0318b118e6392e859ff60849b14713d960530c31e2.jpg (259x194px)\n",
      "  ✓ f007bdb955a65ddf777b308763b910d7c20927d00b5ab72c46751e5457a438dc.jpg (600x400px)\n",
      "  ✓ 496528f8850a2aeb9c0fc1c542a7b2c56785c7d9349f8fff5cd2e661a45cb8ac.jpg (500x329px)\n",
      "  ✓ 0ade894a7c5bfe3e7e8e38bc4006a589a79c68407887d74ed787bcc3cebbb68b.jpg (640x640px)\n",
      "  ✓ 8f95623f1f219a0a11ca0009fa149b7dfd0f58dd1833456a303fa00e92be8e5e.jpg (2560x1920px)\n",
      "  ✓ 87f03fe9a5568bdbba4203b7b82dc585f7dca2227784f3cdf4a2b33b657f862b.jpg (1300x974px)\n",
      "  ✓ d41a59c5d4aaf95509ac2fe99787c56185e2f6d5689a0958a10311f69b41a1fc.jpg (1300x956px)\n",
      "  ✓ 7cfe8c65323be923f528e8f6844a2683b28394884433098d4c600b0936f65892.jpg (799x600px)\n",
      "  ✓ 16f6775769afdd40cf3b0f4a4af317b4acac17ed08c1ed6be08c6437375a3751.jpg (1024x676px)\n",
      "  ✓ 63dd41e4f0fe3fd0b504278f25442ca38600092e04ce32c94e4bf5ba4bda6dc4.jpg (1440x961px)\n",
      "  ✓ 28a0dc8ec0e6db8f458440f50556d85bc5a90c6fccff820357ea352d2d8d4c10.jpg (626x398px)\n",
      "  ✓ b4bd12eed164752c85fd02861efe38a9bbca8574af2d5a93fc940d335ce68276.jpg (1300x1065px)\n",
      "  ✓ f639761566f68da85c77f4b6d3fb01ea9a67e3e763d56424fe20d275d402c215.jpg (1400x933px)\n",
      "  ✓ 30d329c820e4a0804e0094892f9e202a91f492882d80d6cabf06baf6be9729de.jpg (3367x2157px)\n",
      "  ✓ 2b84c420ed621e9503470e712619eca4b98b68829935be023b1d38a3b43fda5d.jpg (478x310px)\n",
      "  ✓ 1047b446e636d874b5d0181cdc28a073df3a0d002249d91c60b34605ec11f6ab.jpg (1600x1143px)\n",
      "  ✓ 2415e33e6da879115fdb6477d60d88cf611b2c68244c01abcb527e984986ce90.jpg (682x1024px)\n",
      "\n",
      "[5] Harvard Hall: Processing 11 images...\n",
      "  ✓ cabc9f508a1bb600d614eb2b7bf26baab3bc07bbe03accdac59add88d217c1c7.jpg (1500x946px)\n",
      "  ✓ 55e8c3a6f1190cedffb338ad633036ac2312392c18f9dd3b4b41452e6f3fb5cb.jpg (1500x1000px)\n",
      "  ✓ 49a49268464e73a1687fb7ddaeb76a4348fea4be787602609292fd719e4b11e9.jpg (277x182px)\n",
      "  ✓ 187fde975da888506dda6fe547c5b647f076a58d191395435df148f8072b8649.jpg (1300x860px)\n",
      "  ✓ 86f0a2c5191dbd02aa53659c9ec26d60e89bdd9f5e34299c61af615b104e5dd1.jpg (1280x960px)\n",
      "  ✓ 701b1408551fd8d644ea31a44e450fd4b2d6e961c640956cc544de2ddbe32683.jpg (1200x800px)\n",
      "  ✓ 00feddd3b37f4863cdec7e4b0466af8180016a6480f1e76e59b0046490338edb.jpg (800x600px)\n",
      "  ✓ 4e71ba9554ea9243701860a8e5bda3d24a97d6e724262109bdc70b484bf6c563.jpg (800x534px)\n",
      "  ✓ a91e9984bb185b896e6d238013e0114079a576febe790f7732277b769c0cd792.jpg (478x310px)\n",
      "  ✓ 91d32e1c976dcbd289a41cedc675c7a33341d5a811465df7c5961c478628b33d.jpg (1920x1080px)\n",
      "  ✓ d752fa67ef8962cf9c1cee25c24e2986a9b87edde73376cf01375de768225ea1.jpg (1024x683px)\n",
      "\n",
      "[6] Harvard Science Center: Processing 17 images...\n",
      "  ✓ 2a642435437145801aa8c8913d437c2c5dba8c3c10c09493796aac79912f87ce.jpg (225x225px)\n",
      "  ✓ d88f5b803b132050d87bd7932e89fdfbb0e02c80d313d4121bf47f5a91eb7512.jpg (1920x685px)\n",
      "  ✓ de1dc4e83513196f1ef2150e61f0ee4766ec6f3f3bd08774da9037aa20c8a5ec.jpg (667x500px)\n",
      "  ✓ 281d20e0b6812d986738cc4ddadb2ef540755f80a9f4e20fa5073a10f9e14d74.jpg (1280x874px)\n",
      "  ✓ 502a0f505ddcb1803f999239213b0eaa7d28ba766a24d98008921a10115616e6.jpg (1920x685px)\n",
      "  ✓ 66130ec19d6c5eb06596698931653a821a18fcf1fb9d1a0c334b282bb0e1f74d.jpg (1920x685px)\n",
      "  ✓ 9d44894fea37048be6ea610ba98d817dd86ac15a90dc9bc9a4d4dbc12f2f94bd.jpg (800x600px)\n",
      "  ✓ 9e405fd5b8da03b0ac5d3a18570002118f2da1cd2f60ec06bd9aa78666632602.jpg (1587x2000px)\n",
      "  ✓ 34fc58e9151a736c7b495a50ca09d371dab23ca928bdf536a7dc1a96463816c6.jpg (274x184px)\n",
      "  ✓ 1d7f20a2a91b5dd0ca8b32cf399d59b0fec551b6f33edcf4c35d1ad09d95842d.jpg (1200x734px)\n",
      "  ✓ b5629fa673c28beb8929d4832a93a93c4f2b3ae402ebb12752291526f578ae81.jpg (960x362px)\n",
      "  ✓ dded83d62d1f04c88d21e3e1c33499ec7e4296621b8e5fe08de9152049388ec7.jpg (270x186px)\n",
      "  ✓ 4672fddf07e7a77b8d40a6fcc9c658f8c7c5eb75546f4726a99a8523f300c3dc.jpg (1500x1000px)\n",
      "  ✓ cc676c0dd0da5b0931ed9bc1f46257a428afbcdae92ba85c8638f65689d572f6.jpg (3000x2059px)\n",
      "  ✓ 08bf818288524bc5bfb1cdbee4c2ff568c46b62a31e4e2f1e5e921a373bb30b6.jpg (640x480px)\n",
      "  ✓ 4bd30fa1b171cf90f30a637f5a3f3a2eb2d65faba67b3e201c91ebafa90668df.jpg (266x190px)\n",
      "  ✓ 7133c08e63c8b3fa3def8d433043c424e7505c32dfd8955d53877d78b680b454.jpg (250x333px)\n",
      "\n",
      "[7] Memorial Hall (Harvard University): Processing 18 images...\n",
      "  ✓ 4944f54712541ff5f2c946554c70fcf34fcac5b747407e78d37d0b98616435a7.jpg (1157x701px)\n",
      "  ✓ 759a7f152ac64af083d0502639970b923143dac33e1519719bfe7213119b3895.jpg (500x648px)\n",
      "  ✓ 5dc3eecec8ed62692d1e94bfdeeb63377132b4726dac4bd28932538984a47b89.jpg (640x427px)\n",
      "  ✓ 97b73ac3c93c4d03f5badf8b985bfdca7092361ad8f0004396f053d5effe530d.jpg (900x500px)\n",
      "  ✓ b74c88724b27c8e7bfa59e4d158a2e34f6d47e3303156dc653a714a72a6cf2bb.jpg (500x332px)\n",
      "  ✓ f04fc751e7daf7cdd4b66d324b0e2419c28ef202aaa32ad30c4d9855ac44f754.jpg (3264x2448px)\n",
      "  ✓ 2c5c8968bbf2bfb6deedfbbf87e3525c9c4cd13870afa5f81ea985f4d27b2b9b.jpg (2937x1960px)\n",
      "  ✓ 970dc656d95a84cb69ab3f82b6712d364ef9090268b98de89a28dca13ec5d38d.jpg (3209x2084px)\n",
      "  ✓ faed518d18dc3bb4e59ce88ee3c28e069b41b32e0f1c65757b8e310d489ec645.jpg (1469x980px)\n",
      "  ✓ e3f668e32544707850a7726d7f6a78639aa318ae09adda390d9bd27572e30111.jpg (568x404px)\n",
      "  ✓ f8fb5f75efe52815fc93a8818041bf5768f9981d84ff56874af206bbb6640cd7.jpg (271x186px)\n",
      "  ✓ 1481af785aa54a53e579f1e58611d828d45ea64e688cb70f7b9abed178bd3105.jpg (800x1200px)\n",
      "  ✓ 6861183d9bcb49a09a9e5a60c71712bb72ad90942baa3c3b96fb67e1fbaa453c.jpg (1200x1600px)\n",
      "  ✓ 8454d6e3a071fe195d443fda3733b53d54670b385eb1183505cc12cbb40b584d.jpg (847x648px)\n",
      "  ✓ f0ea59ea623c6d0fcb27a201b266984f47830b722004cdbc3a535abaec6df681.jpg (330x440px)\n",
      "  ✓ db26f766124daaf40ecc9b5faa0c8194bd2c70c435a7a9f5822e5b7c8a9685a3.jpg (540x838px)\n",
      "  ✓ 54070007219fab76c22efa000775e841dd168b79c3918a1be8ba3c417fa5c5e9.jpg (400x600px)\n",
      "  ✓ cbc6f40e2ee2078aafb36d916abdb65ef0d22aadfb39096280e58a063aab6e15.jpg (266x189px)\n",
      "\n",
      "[8] John Harvard Statue: Processing 14 images...\n",
      "  ✓ 2e0cc6251cd55d1ce8a2cc19cfa94021c01c0091a5d34414aa10053dc1e6f6c5.jpg (2000x1333px)\n",
      "  ✓ 00887ba973418dd26cffa20e8969347c95400e0b14ce9c969b131bf023ce0025.jpg (201x251px)\n",
      "  ✓ 60b2fad105d085d016782d5f1890b123ea756445389c164b1ec9a183354c1c2e.jpg (300x400px)\n",
      "  ✓ dad17c167a3a90afbcc9a43e89f9f2d3dec069d98547d6ac3bf979aa1a98c3a2.jpg (1622x1809px)\n",
      "  ✓ 92b71432991873797c302721622209344aed1d47638390308ceddfa770bb0eb8.jpg (490x800px)\n",
      "  ✓ f93a2b9eebed1258effaed601af55e5917e7c2ebde2e346ed99916af321fb475.jpg (1000x600px)\n",
      "  ✓ f2d46bb5a30b64c29de48cf306aafc4b4ab28a32c5d06e541821d41b85dbb654.jpg (1200x1600px)\n",
      "  ✓ 25780516ebc2e2ca1507f8da34cab32b6470aa53d1866f5765c358c0b090f5e3.jpg (1512x2016px)\n",
      "  ✓ 5b22dc3690e80736d92e50a3d58c344431f2556e07fe1cd2f35977d444bd167f.jpg (2500x1667px)\n",
      "  ✓ 4d1cb084a96b14675d77dce5070480f4dc9162a8ec0e643dbe8a97c85d699692.jpg (1280x988px)\n",
      "  ✓ 826a2b4d143104a380043b95dd84a1bddb66b935f4699a3ea4217d42d17ed447.jpg (1920x1080px)\n",
      "  ✓ 4194707b38a87fe5b0ced5df1fa640e4ac75d5249f16cce8fae0b082821d969a.jpg (2000x1333px)\n",
      "  ✓ cc621f353eee41a9c6d12ed26501ce6df376f15b0c5bc158c47e227fc0fb0f88.jpg (330x483px)\n",
      "  ✓ 4c23f10dd22dc1034a87a112668eb86e76a2a7fae1edca2a216293db4ea8fc0d.jpg (1080x719px)\n",
      "\n",
      "[9] Johnston Gate: Processing 14 images...\n",
      "  ✓ ab44bf8130633b9a4e9b29d347323a0be80bc30cc54232b2e5c8524312006f04.jpg (2048x1367px)\n",
      "  ✓ 620edf3ad537aab6e9f7cb9ce0fdb53f0bd92b2683c66cf817ad330b2d1ed2dd.jpg (250x187px)\n",
      "  ✓ 72f9093d16d1e3478c016336def745f63801f5ee9d30640bdadff3d8725a2306.jpg (1024x679px)\n",
      "  ✓ c35e3b3752cef579e1126f776f6124bdf126c0b15fb3c3905c2609eed8eb709a.jpg (800x600px)\n",
      "  ✓ f1c533cb6fe4fc24e43639abae92272bb75ee4db7fd0e7b60705cfbc6f7d2dc8.jpg (300x168px)\n",
      "  ✓ 647e33c64d39a8b7aaf9e7d97d57e2524ad48896ed99bf68fb0d2f805114d8d9.jpg (1024x598px)\n",
      "  ✓ fcdfd460eb85c1bbee3873af0fa41a51fd027e1fbea5806038713450a80182c4.jpg (640x480px)\n",
      "  ✓ 6a88a0ace020720fcdd6b33d0b692abe466d76d336e1b9e02e1bd74d5d42e453.jpg (1200x1288px)\n",
      "  ✓ 3b4396b648a8d59a15b649c159d29f6e2be19c571f3cc8f5d57dfb345b58c900.jpg (640x427px)\n",
      "  ✓ 41a77e494ff2eb6c06b482315abe904e9359553b1367e840e16f292006177dd3.jpg (275x183px)\n",
      "  ✓ a0d320119747d059a153031ae5ba7c46702b4fc88d50fb63be53454b59115449.jpg (1200x800px)\n",
      "  ✓ 6014f026c2a927f26e5a501e2d863333f3ec3ca9d6c85ddff033876251f0ecf3.jpg (1024x684px)\n",
      "  ✓ afa621e551e5d6b22cd912d89aceae8e7e496a4ebb9890c50202d4a5ae7b7800.jpg (1080x1080px)\n",
      "  ✓ 788676128c94767b8dd475fbc7df94cb2d6dadf78742610947cd4164e7cddc91.jpg (512x384px)\n",
      "\n",
      "[10] Meyer Gate: Processing 4 images...\n",
      "  ✓ cf977a0f58c803f9d85b9dd1df7c81911e878e1b44b54317bf807512a0188a3a.jpg (1498x1000px)\n",
      "  ✓ ff4d354e7ddc0651e8d219b7bd0676c00742b95f2fc500f8a8c8af3cc5140e54.jpg (275x183px)\n",
      "  ✓ c977f253b76cbdea065bfa1e97c0196577207ef3e33808ed4d40241c5500ed98.jpg (281x180px)\n",
      "  ✓ 7884af8876d3a39883ef3ed8ef2415b311fce713b5c57f044e64eb27f818707b.jpg (570x400px)\n",
      "\n",
      "[11] Harvard Art Museums: Processing 6 images...\n",
      "  ✓ 542625bf28e1fab012a4668236b3260f4f9c68c70f49af44f91a3ae2d470eda6.jpg (300x168px)\n",
      "  ✓ 495989470f0dd1933c2a4094cc9bbde178bd8d1fab0dc0687db9f3170945b7ac.jpg (259x194px)\n",
      "  ✓ 19ea0ee649805aa4e147a4fd9165b2842db606262bbcf4d69ed66e30438b240d.jpg (2000x1385px)\n",
      "  ✓ 0c818e4198e53244838f04dc5dfcf99ef951639b292cc221843573a33ba83856.jpg (2560x1440px)\n",
      "  ✓ 7bc0cbbbb45794510f85740afd8b8c52b0ca1c18388e88c03dbe58d3eed01975.jpg (1280x960px)\n",
      "  ✓ ae59f7a4c43896f8bead5fddf10be8b8bc33c73f0778bb16bcf0e787869b765c.jpg (800x450px)\n",
      "\n",
      "[12] Harvard Lampoon Building: Processing 14 images...\n",
      "  ✓ 1fa7bfe073fa084323aadd5864edcb87065b3288b91ff94bb105c9005bcfadcc.jpg (939x900px)\n",
      "  ✓ edcc00e1ac42ed35b7451ee5db39b2bc407fff73495cdd9b18f3a33c1ce237d7.jpg (512x417px)\n",
      "  ✓ 1ddbe67bbc89508b3c492313568372e891762154ac54ef3821bc222befe3dade.jpg (2500x3746px)\n",
      "  ✓ b957f654e1f4e8d38c3c59949774bb68b39aeeab8f6c78cbf7cbf27c61a8f7a7.jpg (1233x1800px)\n",
      "  ✓ 24dbed7d9316103a332c3042d5b37432b37161e87da033b772a54d86960de125.jpg (1000x667px)\n",
      "  ✓ 0a2f9ada12fd6e4df21fd35e37132b513d3857a4f9616eb7ad78fc17e0cb4727.jpg (1200x1600px)\n",
      "  ✓ eaceecdffeb8e287defdddf23897f73f3c5b3337dda2a9f219854135892d50be.jpg (424x600px)\n",
      "  ✓ adf8b9e8a59ee5ec8cfbb0b95d93601d94078b2469ec2094fe9a1bc9622a67b2.jpg (274x184px)\n",
      "  ✓ ae546e786d1b06e3359a8e12250dbea48e7cdde6ad6826d9e8e7a148ad338525.jpg (2048x1536px)\n",
      "  ✓ eb844736c448b784c1d703c1a33df5c6b76a7aa8eb41b097eb287f5215bedb0b.jpg (2464x2974px)\n",
      "  ✓ 21cab088e24c0cd9485f984c8d4b634751ef4d5b76aa7503bd976b38e50b1b52.jpg (250x224px)\n",
      "  ✓ a0d0b8d81ad05fe0ba0ad120892aa3f11521682ba5827da90e468d5c8c612adf.jpg (201x251px)\n",
      "  ✓ f068d45b411a69f650dc37daf45b594f197a51421a06919a48e427d01f546f86.jpg (250x354px)\n",
      "  ✓ d3eeef0d1dcee9eb0026b70b8f0a78786af8926fe6cf21c2491c9d97a592eede.jpg (533x400px)\n",
      "\n",
      "[13] Lowell House: Processing 18 images...\n",
      "  ✓ 58d3d593a5da713aa1aae48e0f6ba37d3b8493ed45ff70b409d3e455a7161f49.jpg (201x251px)\n",
      "  ✓ dcba32e60b3cf6c2a878925a7772cf3673a8ba20b305ea68046712711aa66a69.jpg (199x253px)\n",
      "  ✓ 696c6d129823ab0f910a19dac15c07c8be63a813b8c97a58fbdf3fc30aac8d2f.jpg (1920x1080px)\n",
      "  ✓ dfdda1147c7ee9fc976aa89eb71281db00f3a360290fc90e709538699bfb9407.jpg (480x270px)\n",
      "  ✓ cd6b8b8ed3df66d5030e040cdb9e8fa43df7cb6e881f4756fb9b829c257176ad.jpg (484x733px)\n",
      "  ✓ e86793f328e54c88b1449267969f54fa4625b5e9360ecc17106d0af429834dd3.jpg (1499x1010px)\n",
      "  ✓ 8edac50003631eed989a1ae9219a9e575874159df147522c070729a338d6daa0.jpg (1400x600px)\n",
      "  ✓ 9517d51c1e93a5b90fafe778acb10e5719a487c9b5e665ba6aaf93282443c688.jpg (800x534px)\n",
      "  ✓ e1e348688b4779173ce31815905a950fdf69e714eb65fb49904d35ab55c7dcdd.jpg (250x333px)\n",
      "  ✓ a9a8b1e9584cedbc785ab3294b422aca6d53026f2f2c1aa48aecc3fa0bdd5c77.jpg (640x480px)\n",
      "  ✓ fd8c90d4a3e3606b7bbbae19bd35201a6b1d87d921cb290c4c930cec1488c224.jpg (533x800px)\n",
      "  ✓ 8975f30ced6b75026b5b3db3a5d17bc295e2ef058713658988f2e579bf181b0d.jpg (1280x806px)\n",
      "  ✓ 2216a3ebb2dae995437d5ffbd1e8453f1ae866ad1f8a4381660a42cb26e4d638.jpg (2000x1337px)\n",
      "  ✓ f2d0fd25273975942749d23504e868444fcf51909e77910b5a1af4419dc68e28.jpg (628x700px)\n",
      "  ✓ 21476240da656ab253e4f9acbaa0178b63705974bb9b237b2ccbf6eae02bb37e.jpg (750x1129px)\n",
      "  ✓ 2c0a80b231817f7853e8d462922e2b8bdf0347326a68a0262ead19b3fa36e012.jpg (2560x1707px)\n",
      "  ✓ 293f2ce2ced527a8dff6bb4316a62f6ce9a576b1d4729f14ab6918ec12b0d06d.jpg (1600x900px)\n",
      "  ✓ 6bc6f98285301eda4e4b7f2a703e77ad6c2f77191c6b35eec31bc674f2597642.jpg (550x413px)\n",
      "\n",
      "[14] Weld Boathouse: Processing 8 images...\n",
      "  ✓ a7ebb7d06937fc346eb2b3a0eb97a3ec9a7f1106673519507db90eee22a4139f.jpg (3872x2592px)\n",
      "  ✓ 8f0cf4afd51d1702f80cc3acf420f3fd937564bcc1e3720eb1023525e4043b1d.jpg (310x162px)\n",
      "  ✓ 8dca9997e625ccc662ced9cc2ea40c549e3b7828f5a9bb8d9354e9bda0833489.jpg (1500x999px)\n",
      "  ✓ b57f75efaada699196660c09e595b361197a9a794a72a25454f17ffb47eec6fa.jpg (450x243px)\n",
      "  ✓ e78f1c9458c9bbb72ff6bcd96e24bc7e1551790bb4343f3ee156d8eaa18a4b33.jpg (1500x999px)\n",
      "  ✓ 522104fbc2ee1ca7c3c276b5e0b50a76970a760bae09692e714f2f99450bff6c.jpg (2544x1908px)\n",
      "  ✓ afb75eed7ef82a37cef65d3280c8825e550a966b56d70728e26248e3a2c3af8e.png (970x722px)\n",
      "  ✓ 137724533ff3ce28e05edd3faf28aae992dc024a59671a6925aeabbe492f4b05.png (970x722px)\n",
      "\n",
      "[15] Weeks Footbridge: Processing 12 images...\n",
      "  ✓ beda9b28ade314ec5d9929eb3e58b4fea982d09682a80f2b23e0246cb4797003.jpg (348x348px)\n",
      "  ✓ dee55146d3d95760615192b3222c762dfe72cce4b0c7fe726e38207352321680.jpg (900x600px)\n",
      "  ✓ 6bf5f19495b2e8e057e9590ad621834a78a881f0a5cf2ab461913919bcf341f8.jpg (894x596px)\n",
      "  ✓ 25dacdef83b4f04f4b431a284c0daf79908a258639851dc699bfbc0fb7f26b50.jpg (1000x682px)\n",
      "  ✓ 25f83cb132c995bed0137d40bea79c2ec2178c799908968f6bf14429ad0d9ea1.jpg (626x385px)\n",
      "  ✓ 8ac871b3b971d1917ac7b0769f986306a9cc75a1520a60cdad5d25b5bcb82720.jpg (1500x1000px)\n",
      "  ✓ 9e12285f36509a2f2c4a949e1703f5fc98b958ccbe8298cee9607a05b35c4c0c.jpg (2560x1920px)\n",
      "  ✓ bfc6faf4bc34cb79cdcc1a473ab6a6efe2dca5a87a2667ecc280a3b5cdc47bde.jpg (626x418px)\n",
      "  ✓ fd1e74efb85b60c0ba48f0db925514e0922be51445873aa699f38266d85457d5.jpg (2000x1333px)\n",
      "  ✓ e2961b06267d8d3690226fd79b54848369c72cbc90d259bba2227e2b97624f8a.jpg (540x360px)\n",
      "  ✓ e6f75ade164bb6caebaa194e0bd9f03b59f07d1534ef6883d6079b1e18c2c6f3.jpg (1024x682px)\n",
      "  ✓ 3bac18232453a34ca13cdd9338936171c74951e74ce2825f76e4ffa700eafe58.jpg (6240x4160px)\n",
      "\n",
      "[16] Langdell Hall: Processing 14 images...\n",
      "  ✓ df8ce5d02b04918901333aa3a606fd8a9480b9f2db72d72455a088b9b6e75039.jpg (1920x2560px)\n",
      "  ✓ 17cee5e28f2f57a6d291796c97742d61ed5ce164f8ee61efba7068eaf5faaa7c.jpg (2816x2112px)\n",
      "  ✓ 322fc23d95cc549f093dd7fde939853f79b1348faa22649157c23b11b473ebfa.jpg (2400x1947px)\n",
      "  ✓ 9e39971968c643877c166bbcc743cf890815dd44aa37ed6cd976243f641db109.jpg (1024x768px)\n",
      "  ✓ 1fd9bbbdf14c9c4cfa4ae20eeba9214c562c83f23de7c26b09fa91c600b7d6fe.jpg (1499x999px)\n",
      "  ✓ 8e83f34bbfd56d4503f0ca7c8b0b48949344517a0e5f125274d65740b27154e3.jpg (275x183px)\n",
      "  ✓ 8ee6836247c7e5aac166e7f2f70a51eec886eb191f0c8415da0654083d26c1e1.jpg (1440x964px)\n",
      "  ✓ 41f0ea080b3c9020045a33b5a6d33522b205e0ed3f666db540a9b4f593550ec5.jpg (2000x1333px)\n",
      "  ✓ c431322cdcb458dfae6eae3cd0a4232ef6ee16f46a2c9484683832afc47eb146.jpg (3600x1756px)\n",
      "  ✓ 1e30c62a2fbcf2ebd740eb2531741aa2e9b18b650ae62102f3a85e71b66bb017.jpg (292x173px)\n",
      "  ✓ 9dab5e1c1233c2b02244b354a79c954de5ce5436047bbdafbb0474de7864fe6b.jpg (1539x1600px)\n",
      "  ✓ 299a093e096d26203ca7984a99fd3b02fed253b0457f6c854fb2a01a721406ca.jpg (1300x956px)\n",
      "  ✓ a1f709afe431820f5abe96d3702eac54d82af8df2e3e971378aa6b5e1c9a847e.jpg (500x375px)\n",
      "  ✓ 7f4e5fc3b32d68089dee347669b178a8971c9ff8080ad108e7ea86b88d20beca.jpg (250x166px)\n",
      "\n",
      "[17] Smith Campus Center: Processing 10 images...\n",
      "  ✓ 15d6bc5497cb4c281cb97c7281e6ae36a84c66acedec8388131d9a2a7ca9d74a.jpg (1280x962px)\n",
      "  ✓ bc0c0d7aaffb77828778ed2ddcc297ef5cd2a045090c348a54d917f3862edc3e.jpg (1200x800px)\n",
      "  ✓ 9d444df0deec58bf745b93887889f1d220aaaebda588ca2f06d7d991a15b05f0.jpg (696x425px)\n",
      "  ✓ bcf255c227b5af0c55f639379877b7131ec06a5504f1088ff02db1a65799ec59.jpg (880x500px)\n",
      "  ✓ 33451e1112bd9ffee702db8633e81a1729d763033b5929f5e60729d5e82d55d4.jpg (2120x1590px)\n",
      "  ✓ 3a3ad1dd2e48b2a098596b21b967a124d30126c232b305114d8b60bb879d8c9d.jpg (225x225px)\n",
      "  ✓ ef25e4d37040c54dd3094a67043cc7c947a506aa72a8faaf47820eddf42ae877.jpg (1000x667px)\n",
      "  ✓ f79d28ff02301e0a86016650c409c54b648f1c8948d62d38ffd09456f465e8ff.jpg (800x533px)\n",
      "  ✓ 584e30eb0b3cc0a9b7372345bdaedd55df545c504317ebc0c37e367047672020.jpg (282x179px)\n",
      "  ✓ fc361cf5673202cc4654b55a41159dd92fad02362f097ad801e3d223abf90da7.jpg (275x183px)\n",
      "\n",
      "[18] Science and Engineering Complex: Processing 14 images...\n",
      "  ✓ e550e6fa2dbd9debfe72cd55bfc950369874a5233381235dfec9665001f8c443.jpg (1024x683px)\n",
      "  ✓ e32b4504cdbb9e3b7519259ce7d832e22a4687ac04231aa2b5149166493d2b8a.jpg (2500x1667px)\n",
      "  ✓ 9fe153e106eb2287d2ea47d26c35de1ac1e235314248b1a089b927c1fc7e1a34.jpg (1500x1000px)\n",
      "  ✓ ae3147670f0f4d484b6598c02b20a2b208c57c87c8da4e5e7274cb68f1809def.jpg (1836x1000px)\n",
      "  ✓ 743858be0ca04bdc77d5fb838ded36a9fd0d9ab5dd8c7a75cbd1a53eda7edcd8.jpg (900x600px)\n",
      "  ✓ c46ed67dac79fdb794f9ee44ffc38c7fdd3d57254d219f5684436828c43338ec.jpg (667x1000px)\n",
      "  ✓ 58367fb785fc4dadb25b6d857c558260a96b21f964695a514fcb98feb8f0fed4.jpg (310x162px)\n",
      "  ✓ 55aecfa441629b195277fa77fae30f600d52ec86ae67a575108c96690a8773dd.jpg (750x500px)\n",
      "  ✓ 9b044589b28acff8191dddcaa5537a485079631a7d8be0d9e12e92ffdf1f1d62.jpg (2000x1333px)\n",
      "  ✓ 70a9a0d902b038c192afbca79285cb3297ccbef7e38a4c18b5e61b434df229c3.jpg (1024x683px)\n",
      "  ✓ 87c50cf2d4974fb4732673683fc0a37c179b920cb29263da82f39204bb3d4c1c.jpg (1050x700px)\n",
      "  ✓ d3798d9a0f1d93b4fa2210b25ec21321dba694a0e2a29cfdec1e840e45bac1a2.jpg (1024x683px)\n",
      "  ✓ 1b2c3ddbb4cc7580a70ebe8a8a87ee78ddf4f69bb7eb0faf258e0af31eba51d0.jpg (512x341px)\n",
      "  ✓ e3effd1b9237500ad608193808bd880be1e71a455da1308d285bb44f621c5bfc.jpg (1500x999px)\n",
      "\n",
      "✓ Created image_manifest.csv with 242 images\n",
      "\n",
      "============================================================\n",
      "IMAGE PROCESSING SUMMARY\n",
      "============================================================\n",
      "Buildings with images: 18/18\n",
      "Total images: 242\n",
      "Valid images: 242\n",
      "Invalid images: 0\n",
      "Images renamed: 2\n",
      "Avg per building: 13.4\n"
     ]
    }
   ],
   "source": [
    "# Cell 7: Process Manual Images (from existing CSVs)\n",
    "\n",
    "def validate_image_file(img_path: Path) -> Optional[Dict]:\n",
    "    \"\"\"Validate image meets quality requirements.\"\"\"\n",
    "    try:\n",
    "        with Image.open(img_path) as img:\n",
    "            if img.format not in ('JPEG', 'PNG', 'WebP'):\n",
    "                print(f\"  ✗ {img_path.name}: Invalid format ({img.format})\")\n",
    "                return None\n",
    "            size_bytes = img_path.stat().st_size\n",
    "            return {'width': img.width, 'height': img.height, 'format': img.format, 'size_bytes': size_bytes}\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"  ✗ {img_path.name}: Error - {e}\")\n",
    "        return None\n",
    "\n",
    "def compute_sha256(file_path: Path) -> str:\n",
    "    \"\"\"Compute SHA256 hash for deduplication.\"\"\"\n",
    "    sha256_hash = hashlib.sha256()\n",
    "    with open(file_path, \"rb\") as f:\n",
    "        for byte_block in iter(lambda: f.read(4096), b\"\"):\n",
    "            sha256_hash.update(byte_block)\n",
    "    return sha256_hash.hexdigest()\n",
    "\n",
    "def process_manual_images_from_csv(output_dir: Path) -> Tuple[List[Dict], Dict]:\n",
    "    \"\"\"Scan, validate, hash, and rename images using existing CSV data.\"\"\"\n",
    "    # Read buildings from CSV\n",
    "    buildings_csv = output_dir / \"buildings_names_metadata.csv\"\n",
    "    if not buildings_csv.exists():\n",
    "        print(f\"⚠ {buildings_csv} not found\")\n",
    "        return [], {}\n",
    "    \n",
    "    buildings_df = pd.read_csv(buildings_csv)\n",
    "    \n",
    "    manifest_records = []\n",
    "    stats = {\n",
    "        'total_buildings': len(buildings_df),\n",
    "        'buildings_with_images': 0,\n",
    "        'total_images': 0,\n",
    "        'valid_images': 0,\n",
    "        'invalid_images': 0,\n",
    "        'renamed_count': 0\n",
    "    }\n",
    "    \n",
    "    images_dir = output_dir / \"images\"\n",
    "    \n",
    "    for _, row in buildings_df.iterrows():\n",
    "        building_id = row['id']\n",
    "        building_name = row['name']\n",
    "        qid = row.get('wikibase_item', '')\n",
    "        \n",
    "        building_dir = images_dir / str(building_id)\n",
    "        \n",
    "        if not building_dir.exists():\n",
    "            continue\n",
    "        \n",
    "        # Find all image files\n",
    "        image_files = (list(building_dir.glob('*.jpg')) + list(building_dir.glob('*.jpeg')) + \n",
    "                      list(building_dir.glob('*.png')) + list(building_dir.glob('*.webp')) +\n",
    "                      list(building_dir.glob('*.JPG')) + list(building_dir.glob('*.PNG')))\n",
    "        \n",
    "        if not image_files:\n",
    "            print(f\"[{building_id}] {building_name}: No images\")\n",
    "            continue\n",
    "        \n",
    "        print(f\"\\n[{building_id}] {building_name}: Processing {len(image_files)} images...\")\n",
    "        stats['buildings_with_images'] += 1\n",
    "        \n",
    "        for img_path in image_files:\n",
    "            stats['total_images'] += 1\n",
    "            metadata = validate_image_file(img_path)\n",
    "            if not metadata:\n",
    "                stats['invalid_images'] += 1\n",
    "                continue\n",
    "            \n",
    "            img_hash = compute_sha256(img_path)\n",
    "            ext = img_path.suffix.lower()\n",
    "            if ext == '.jpeg':\n",
    "                ext = '.jpg'\n",
    "            new_filename = f\"{img_hash}{ext}\"\n",
    "            new_path = building_dir / new_filename\n",
    "            original_filename = img_path.name\n",
    "            \n",
    "            if img_path.name != new_filename:\n",
    "                img_path.rename(new_path)\n",
    "                stats['renamed_count'] += 1\n",
    "            \n",
    "            mime_map = {'.jpg': 'image/jpeg', '.png': 'image/png', '.webp': 'image/webp'}\n",
    "            manifest_records.append({\n",
    "                'building_id': building_id,\n",
    "                'building_name': building_name,\n",
    "                'qid': qid if pd.notna(qid) else '',\n",
    "                'image_hash': img_hash,\n",
    "                'filename': new_filename,\n",
    "                'original_filename': original_filename,\n",
    "                'local_path': f\"/data_manual/images/{building_id}/{new_filename}\",\n",
    "                'url': '',\n",
    "                'width': metadata['width'],\n",
    "                'height': metadata['height'],\n",
    "                'size_bytes': metadata['size_bytes'],\n",
    "                'mime_type': mime_map.get(ext, 'image/jpeg')\n",
    "            })\n",
    "            stats['valid_images'] += 1\n",
    "            print(f\"  ✓ {new_filename} ({metadata['width']}x{metadata['height']}px)\")\n",
    "    \n",
    "    return manifest_records, stats\n",
    "\n",
    "def generate_image_manifest(manifest_records: List[Dict], output_dir: Path) -> Path:\n",
    "    \"\"\"Generate image_manifest.csv with exact schema.\"\"\"\n",
    "    manifest_path = output_dir / \"images\" / \"image_manifest.csv\"\n",
    "    with open(manifest_path, 'w', newline='', encoding='utf-8') as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=[\n",
    "            'building_id', 'building_name', 'qid', 'image_hash', 'filename', 'original_filename',\n",
    "            'local_path', 'url', 'width', 'height', 'size_bytes', 'mime_type'\n",
    "        ])\n",
    "        writer.writeheader()\n",
    "        writer.writerows(manifest_records)\n",
    "    return manifest_path\n",
    "\n",
    "# Main execution\n",
    "if not OUTPUT_DIR.exists():\n",
    "    print(f\"⚠ {OUTPUT_DIR} doesn't exist\")\n",
    "else:\n",
    "    print(\"Processing manual images from existing CSVs...\\n\" + \"=\"*60)\n",
    "    manifest_records, image_stats = process_manual_images_from_csv(OUTPUT_DIR)\n",
    "    \n",
    "    if manifest_records:\n",
    "        manifest_path = generate_image_manifest(manifest_records, OUTPUT_DIR)\n",
    "        print(f\"\\n✓ Created {manifest_path.name} with {len(manifest_records)} images\")\n",
    "    else:\n",
    "        print(\"\\n⚠ No valid images found\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"IMAGE PROCESSING SUMMARY\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Buildings with images: {image_stats['buildings_with_images']}/{image_stats['total_buildings']}\")\n",
    "    print(f\"Total images: {image_stats['total_images']}\")\n",
    "    print(f\"Valid images: {image_stats['valid_images']}\")\n",
    "    print(f\"Invalid images: {image_stats['invalid_images']}\")\n",
    "    print(f\"Images renamed: {image_stats['renamed_count']}\")\n",
    "    if image_stats['valid_images'] > 0:\n",
    "        avg = image_stats['valid_images'] / max(1, image_stats['buildings_with_images'])\n",
    "        print(f\"Avg per building: {avg:.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "MANUAL CURATION SUMMARY\n",
      "============================================================\n",
      "\n",
      "📍 Output: /Users/hughv/Documents/Harvard/AC215/ac215_HistoriCam/data_manual\n",
      "\n",
      "🏛️  Buildings/Statues: 18\n",
      "\n",
      "📸 Images: 242\n",
      "    Average per building: 13.4\n",
      "\n",
      "📄 Files:\n",
      "  ✓ buildings_names.csv\n",
      "  ✓ buildings_names_metadata.csv\n",
      "  ✓ buildings_info.csv (stub)\n",
      "  ✓ images/image_manifest.csv\n",
      "\n",
      "✅ Schema Validation:\n",
      "  All schemas valid ✓\n",
      "\n",
      "============================================================\n",
      "NEXT STEPS:\n",
      "============================================================\n",
      "1. Review generated CSVs for accuracy\n",
      "2. Use /data_manual/ as drop-in replacement for /data/\n",
      "3. Test with your ML pipeline\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Cell 8: Validation and Summary\n",
    "\n",
    "def validate_csv_schemas(output_dir: Path) -> Dict:\n",
    "    \"\"\"Validate CSVs match expected schemas.\"\"\"\n",
    "    issues = []\n",
    "    \n",
    "    names_path = output_dir / \"buildings_names.csv\"\n",
    "    if not names_path.exists():\n",
    "        issues.append(\"buildings_names.csv not found\")\n",
    "    else:\n",
    "        df = pd.read_csv(names_path)\n",
    "        expected = [\"id\", \"name\", \"source_url\", \"last_seen\", \"source\"]\n",
    "        if list(df.columns) != expected:\n",
    "            issues.append(f\"buildings_names.csv: column mismatch\")\n",
    "        if not (df['id'] == range(1, len(df) + 1)).all():\n",
    "            issues.append(\"buildings_names.csv: IDs not sequential\")\n",
    "    \n",
    "    metadata_path = output_dir / \"buildings_names_metadata.csv\"\n",
    "    if not metadata_path.exists():\n",
    "        issues.append(\"buildings_names_metadata.csv not found\")\n",
    "    else:\n",
    "        df2 = pd.read_csv(metadata_path)\n",
    "        expected2 = [\"id\", \"name\", \"source_url\", \"last_seen\", \"source\", \"latitude\", \"longitude\", \"aliases\", \"wikibase_item\"]\n",
    "        if list(df2.columns) != expected2:\n",
    "            issues.append(\"buildings_names_metadata.csv: column mismatch\")\n",
    "    \n",
    "    manifest_path = output_dir / \"images\" / \"image_manifest.csv\"\n",
    "    manifest_df = None\n",
    "    if not manifest_path.exists():\n",
    "        issues.append(\"images/image_manifest.csv not found\")\n",
    "    else:\n",
    "        manifest_df = pd.read_csv(manifest_path)\n",
    "        expected3 = [\"building_id\", \"building_name\", \"qid\", \"image_hash\", \"filename\", \"original_filename\",\n",
    "                    \"local_path\", \"url\", \"width\", \"height\", \"size_bytes\", \"mime_type\"]\n",
    "        if list(manifest_df.columns) != expected3:\n",
    "            issues.append(\"image_manifest.csv: column mismatch\")\n",
    "    \n",
    "    return {\n",
    "        'valid': len(issues) == 0,\n",
    "        'issues': issues,\n",
    "        'buildings_count': len(df) if names_path.exists() else 0,\n",
    "        'images_count': len(manifest_df) if manifest_df is not None else 0\n",
    "    }\n",
    "\n",
    "def generate_summary_report(pages, validation_results, output_dir: Path):\n",
    "    \"\"\"Generate comprehensive summary.\"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"MANUAL CURATION SUMMARY\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"\\n📍 Output: {output_dir}\")\n",
    "    print(f\"\\n🏛️  Buildings/Statues: {validation_results['buildings_count']}\")\n",
    "    \n",
    "    if pages:\n",
    "        types = {}\n",
    "        for p in pages:\n",
    "            t = p.get('manual_type', 'unknown')\n",
    "            types[t] = types.get(t, 0) + 1\n",
    "        for t, count in types.items():\n",
    "            print(f\"    - {t}: {count}\")\n",
    "    \n",
    "    print(f\"\\n📸 Images: {validation_results['images_count']}\")\n",
    "    if validation_results['buildings_count'] > 0 and validation_results['images_count'] > 0:\n",
    "        avg = validation_results['images_count'] / validation_results['buildings_count']\n",
    "        print(f\"    Average per building: {avg:.1f}\")\n",
    "    \n",
    "    print(f\"\\n📄 Files:\")\n",
    "    print(f\"  ✓ buildings_names.csv\")\n",
    "    print(f\"  ✓ buildings_names_metadata.csv\")\n",
    "    print(f\"  ✓ buildings_info.csv (stub)\")\n",
    "    if validation_results['images_count'] > 0:\n",
    "        print(f\"  ✓ images/image_manifest.csv\")\n",
    "    \n",
    "    print(f\"\\n✅ Schema Validation:\")\n",
    "    if validation_results['valid']:\n",
    "        print(\"  All schemas valid ✓\")\n",
    "    else:\n",
    "        print(\"  Issues found:\")\n",
    "        for issue in validation_results['issues']:\n",
    "            print(f\"    - {issue}\")\n",
    "    \n",
    "    if pages:\n",
    "        has_coords = sum(1 for p in pages if p.get('lat') and p.get('lon'))\n",
    "        has_qid = sum(1 for p in pages if p.get('qid'))\n",
    "        print(f\"\\n🗺️  Coordinates: {has_coords}/{len(pages)} ({100*has_coords/len(pages):.0f}%)\")\n",
    "        print(f\"🔗 Wikidata QIDs: {has_qid}/{len(pages)} ({100*has_qid/len(pages):.0f}%)\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"NEXT STEPS:\")\n",
    "    print(\"=\"*60)\n",
    "    print(\"1. Review generated CSVs for accuracy\")\n",
    "    print(\"2. Use /data_manual/ as drop-in replacement for /data/\")\n",
    "    print(\"3. Test with your ML pipeline\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "if OUTPUT_DIR.exists():\n",
    "    validation = validate_csv_schemas(OUTPUT_DIR)\n",
    "    generate_summary_report(found_pages if 'found_pages' in dir() else [], validation, OUTPUT_DIR)\n",
    "else:\n",
    "    print(f\"⚠ {OUTPUT_DIR} doesn't exist. Run previous cells first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.13.5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
