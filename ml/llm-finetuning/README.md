# LLM Fine-tuning

Fine tuning produces a slightly more personable tour guide with character as opposed to the generic Gemini. There is some reason to favor this, although we have not implemented integration of this fine tuned model yet. For the purposes of cost and simplicity, there is a good chance that we do not use the fine tuned model as the gains are not that significant.

Training Accuracy:
<img src="images/accuracy.png"  width="800">

Training Number of Predictions:
<img src="images/numPredictions.png"  width="800">

Training Loss:
<img src="images/loss.png"  width="800">

Data distribution:
<img src="images/dataDistribution.png"  width="800">

